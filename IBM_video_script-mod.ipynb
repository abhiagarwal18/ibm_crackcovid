{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 272
    },
    "colab_type": "code",
    "id": "vQrQiDONMdlT",
    "outputId": "7c6b3aad-8d3e-406b-d412-c81b885eee94"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: cloudant in /home/hrohmetra/anaconda3/envs/ibm/lib/python3.6/site-packages (2.13.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.7.0 in /home/hrohmetra/anaconda3/envs/ibm/lib/python3.6/site-packages (from cloudant) (2.23.0)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/hrohmetra/anaconda3/envs/ibm/lib/python3.6/site-packages (from requests<3.0.0,>=2.7.0->cloudant) (1.25.9)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /home/hrohmetra/anaconda3/envs/ibm/lib/python3.6/site-packages (from requests<3.0.0,>=2.7.0->cloudant) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/hrohmetra/anaconda3/envs/ibm/lib/python3.6/site-packages (from requests<3.0.0,>=2.7.0->cloudant) (2.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/hrohmetra/anaconda3/envs/ibm/lib/python3.6/site-packages (from requests<3.0.0,>=2.7.0->cloudant) (2020.4.5.1)\n",
      "Requirement already satisfied: python-googlegeocoder in /home/hrohmetra/anaconda3/envs/ibm/lib/python3.6/site-packages (0.4.0)\n",
      "Requirement already satisfied: six>=1.4.1 in /home/hrohmetra/anaconda3/envs/ibm/lib/python3.6/site-packages (from python-googlegeocoder) (1.15.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install cloudant\n",
    "!pip install python-googlegeocoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "app.js\t\t\t\t\t       node_modules\t  public\r\n",
      "flea_market_pedestrians_summer_people_415.mp4  package.json\t  README.md\r\n",
      "IBM_video_script.ipynb\t\t\t       package-lock.json\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9tQTv9r3QTvL"
   },
   "outputs": [],
   "source": [
    "import cv2     # for capturing videos\n",
    "import math   # for mathematical operations\n",
    "import matplotlib.pyplot as plt    # for plotting the images\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np    # for mathematical operations\n",
    "import cloudant\n",
    "from cloudant.client import Cloudant\n",
    "from cloudant.error import CloudantException\n",
    "from cloudant.result import Result, ResultByKey\n",
    "import requests\n",
    "import json\n",
    "from googlegeocoder import GoogleGeocoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GTdbQAhPQffR"
   },
   "outputs": [],
   "source": [
    "#service credentials for cloudant \n",
    "serviceUsername = \"db2759e7-f377-4cc4-8946-0f8a93271340-bluemix\"\n",
    "apiKey = \"artElYzY8KxkbtwR8cAqdjQmGC_TmPDwoz3hX_BuA8oU\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FfXbmEInQqOo"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "if using IBM legacy credentials\n",
    "\n",
    "client = Cloudant(serviceUsername, servicePassword, url=serviceURL)\n",
    "client.connect()\n",
    "\n",
    "\"\"\" \n",
    "\n",
    "# if using IAM authentication:\n",
    "\n",
    "client = Cloudant.iam(serviceUsername, apiKey)\n",
    "client.connect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "7KmMUqQLM0EV",
    "outputId": "876f58ad-51be-4ac6-d4bd-3d3f8d2fe62b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'db_videocam' successfully created.\n"
     ]
    }
   ],
   "source": [
    "#if want to create a new database\n",
    "database_name = \"db_videocam\"\n",
    "my_database = client.create_database(database_name)\n",
    "if my_database.exists():\n",
    "   print(f\"'{database_name}' successfully created.\")\n",
    "  \n",
    "# Open an existing database\n",
    "my_database = client['db_videocam']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "NSlWbjZXQx_s",
    "outputId": "7cb6ee40-cc30-4280-d05a-c5e1abae71ba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<GeocoderResult: Vivek Vihar, Delhi, 110095, India>]\n"
     ]
    }
   ],
   "source": [
    "#get latitude and longitude\n",
    "geocoder = GoogleGeocoder(\"AIzaSyBBaFr4NE35DZz-DW3K3WUObRAZGB9f3Sc\")\n",
    "location = \"Super bazar d block vivek vihar\"\n",
    "search = geocoder.get(location) #video camera owner needs to enter address\n",
    "print(search)\n",
    "# print(search[0].geometry.location.lat, search[0].geometry.location.lng)\n",
    "latitude = search[0].geometry.location.lat\n",
    "longitude = search[0].geometry.location.lng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "app.js\t\t\t\t\t       load_model    package-lock.json\r\n",
      "correct_inc.jpeg\t\t\t       models\t     public\r\n",
      "flea_market_pedestrians_summer_people_415.mp4  node_modules  README.md\r\n",
      "IBM_video_script.ipynb\t\t\t       package.json  utils\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hrohmetra/anaconda3/envs/torchy1.5/lib/python3.8/site-packages/torch/serialization.py:657: SourceChangeWarning: source code of class 'MainModel.KitModel' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/home/hrohmetra/anaconda3/envs/torchy1.5/lib/python3.8/site-packages/torch/serialization.py:657: SourceChangeWarning: source code of class 'torch.nn.modules.conv.Conv2d' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import time\n",
    "\n",
    "import argparse\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from utils.anchor_generator import generate_anchors\n",
    "from utils.anchor_decode import decode_bbox\n",
    "from utils.nms import single_class_non_max_suppression\n",
    "from load_model.pytorch_loader import load_pytorch_model, pytorch_inference\n",
    "\n",
    "# model = load_pytorch_model('models/face_mask_detection.pth');\n",
    "model = load_pytorch_model('models/model360.pth');\n",
    "# anchor configuration\n",
    "#feature_map_sizes = [[33, 33], [17, 17], [9, 9], [5, 5], [3, 3]]\n",
    "feature_map_sizes = [[45, 45], [23, 23], [12, 12], [6, 6], [4, 4]]\n",
    "anchor_sizes = [[0.04, 0.056], [0.08, 0.11], [0.16, 0.22], [0.32, 0.45], [0.64, 0.72]]\n",
    "anchor_ratios = [[1, 0.62, 0.42]] * 5\n",
    "\n",
    "# generate anchors\n",
    "anchors = generate_anchors(feature_map_sizes, anchor_sizes, anchor_ratios)\n",
    "\n",
    "# for inference , the batch size is 1, the model output shape is [1, N, 4],\n",
    "# so we expand dim for anchors to [1, anchor_num, 4]\n",
    "anchors_exp = np.expand_dims(anchors, axis=0)\n",
    "\n",
    "id2class = {0: 'Mask', 1: 'NoMask'}\n",
    "\n",
    "\n",
    "def inference(image,\n",
    "              conf_thresh=0.5,\n",
    "              iou_thresh=0.4,\n",
    "              target_shape=(160, 160),\n",
    "              draw_result=True,\n",
    "              show_result=True\n",
    "              ):\n",
    "    '''\n",
    "    Main function of detection inference\n",
    "    :param image: 3D numpy array of image\n",
    "    :param conf_thresh: the min threshold of classification probabity.\n",
    "    :param iou_thresh: the IOU threshold of NMS\n",
    "    :param target_shape: the model input size.\n",
    "    :param draw_result: whether to daw bounding box to the image.\n",
    "    :param show_result: whether to display the image.\n",
    "    :return:\n",
    "    '''\n",
    "    # image = np.copy(image)\n",
    "    output_info = []\n",
    "    height, width, _ = image.shape\n",
    "    image_resized = cv2.resize(image, target_shape)\n",
    "    image_np = image_resized / 255.0  # 归一化到0~1\n",
    "    image_exp = np.expand_dims(image_np, axis=0)\n",
    "\n",
    "    image_transposed = image_exp.transpose((0, 3, 1, 2))\n",
    "\n",
    "    y_bboxes_output, y_cls_output = pytorch_inference(model, image_transposed)\n",
    "    # remove the batch dimension, for batch is always 1 for inference.\n",
    "    y_bboxes = decode_bbox(anchors_exp, y_bboxes_output)[0]\n",
    "    y_cls = y_cls_output[0]\n",
    "    # To speed up, do single class NMS, not multiple classes NMS.\n",
    "    bbox_max_scores = np.max(y_cls, axis=1)\n",
    "    bbox_max_score_classes = np.argmax(y_cls, axis=1)\n",
    "\n",
    "    # keep_idx is the alive bounding box after nms.\n",
    "    keep_idxs = single_class_non_max_suppression(y_bboxes,\n",
    "                                                 bbox_max_scores,\n",
    "                                                 conf_thresh=conf_thresh,\n",
    "                                                 iou_thresh=iou_thresh,\n",
    "                                                 )\n",
    "    safe=0\n",
    "    unsafe=0\n",
    "    for idx in keep_idxs:\n",
    "        conf = float(bbox_max_scores[idx])\n",
    "        class_id = bbox_max_score_classes[idx]\n",
    "        bbox = y_bboxes[idx]\n",
    "        # clip the coordinate, avoid the value exceed the image boundary.\n",
    "        xmin = max(0, int(bbox[0] * width))\n",
    "        ymin = max(0, int(bbox[1] * height))\n",
    "        xmax = min(int(bbox[2] * width), width)\n",
    "        ymax = min(int(bbox[3] * height), height)\n",
    "        if draw_result:\n",
    "            if class_id == 0:\n",
    "                color = (0, 255, 0)\n",
    "                safe=safe+1\n",
    "            else:\n",
    "                color = (255, 0, 0)\n",
    "                unsafe=unsafe+1\n",
    "            cv2.rectangle(image, (xmin, ymin), (xmax, ymax), color, 2)\n",
    "            cv2.putText(image, \"%s: %.2f\" % (id2class[class_id], conf), (xmin + 2, ymin - 2),cv2.FONT_HERSHEY_SIMPLEX, 0.8, color)\n",
    "        output_info.append([class_id, conf, xmin, ymin, xmax, ymax])\n",
    "\n",
    "    no_people=safe+unsafe\n",
    "    if(no_people>0):\n",
    "        score=(safe/(unsafe+safe))*100\n",
    "    print(safe)\n",
    "    print(no_people)\n",
    "    if show_result:\n",
    "        Image.fromarray(image).show()\n",
    "    return output_info\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hrohmetra/anaconda3/envs/torchy1.5/lib/python3.8/site-packages/torch/nn/functional.py:1569: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[1, 0.9918513894081116, 168, 19, 215, 82],\n",
       " [0, 0.949604332447052, 22, 21, 73, 80]]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = cv2.imread(\"correct_inc.jpeg\")\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "inference(img, show_result=False, target_shape=(360, 360))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aVf_bHffNO7b"
   },
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (<ipython-input-1-7a3972a86fc7>, line 31)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-7a3972a86fc7>\"\u001b[0;36m, line \u001b[0;32m31\u001b[0m\n\u001b[0;31m    if (idx>total_frames):\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "video_path=\"flea_market_pedestrians_summer_people_415.mp4\"\n",
    "conf_thresh=0.5\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "height = cap.get(cv2.CAP_PROP_FRAME_HEIGHT)\n",
    "width = cap.get(cv2.CAP_PROP_FRAME_WIDTH)\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "#writer = cv2.VideoWriter(output_video_name, fourcc, int(fps), (int(width), int(height)))\n",
    "total_frames = cap.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "status = True\n",
    "idx = 0\n",
    "while status:\n",
    "    start_stamp = time.time()\n",
    "    status, img_raw = cap.read()\n",
    "    img_raw = cv2.cvtColor(img_raw, cv2.COLOR_BGR2RGB)\n",
    "    read_frame_stamp = time.time()\n",
    "    if (status):\n",
    "        inference(img_raw,\n",
    "                  conf_thresh,\n",
    "                  iou_thresh=0.5,\n",
    "                  target_shape=(360, 360),\n",
    "                  draw_result=True,\n",
    "                  show_result=False)\n",
    "        cv2.imshow('image', img_raw[:, :, ::-1])\n",
    "        cv2.waitKey(1)       \n",
    "        inference_stamp = time.time()\n",
    "        idx += 1\n",
    "        print(\"%d of %d\" % (idx, total_frames))\n",
    "        print(\"read_frame:%f, infer time:%f \" % (read_frame_stamp - start_stamp,\n",
    "                                                               inference_stamp - read_frame_stamp))\n",
    "         if (idx>total_frames):\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "-NGo_EWhWoT5",
    "outputId": "7dc4c693-2531-4f79-dc0b-4b0cb98d157c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document successfully created.\n"
     ]
    }
   ],
   "source": [
    "# Create a JSON document that represents all the data in the row.\n",
    "json_document = {\n",
    "    \"location\": location,\n",
    "    \"latitude\": latitude,\n",
    "    \"longitude\": longitude,\n",
    "    \"people\": no_people,\n",
    "    \"safetyscore\": score\n",
    "}\n",
    "\n",
    "# Check if the document with same location exists in the database\n",
    "doc_exists = 0\n",
    "for doc in my_database:\n",
    "  if((doc['location']==location) or ((doc['latitude']==latitude) and (doc['longitude']==longitude))):\n",
    "    print(\"location {} exists in the database\".format(location))\n",
    "    doc_exists = 1\n",
    "    break\n",
    "\n",
    "if doc_exists == 1: #update existing document\n",
    "  doc['no of people'] = no_people\n",
    "  doc['percentage of people wearing masks'] = percent_wearing_masks\n",
    "  doc.save()\n",
    "  # Check that the document exists in the database.\n",
    "  if new_document.exists():\n",
    "    print(f\"Document successfully updated.\")\n",
    "\n",
    "else:\n",
    "  new_document = my_database.create_document(json_document) #create a document using the Database API.\n",
    "  # Check that the document exists in the database.\n",
    "  if new_document.exists():\n",
    "    print(f\"Document successfully created.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "IBM_video_script.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
